{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re,os,pathlib\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "#‘I’是手动加的\n",
    "\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O','I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinyin2char = {'Anhui':'皖',\n",
    " 'Beijing':'京',\n",
    " 'Chongqing':'渝',\n",
    " 'Fujian':'闽',\n",
    " 'Gansu':'甘',\n",
    " 'Guangdong':'粤',\n",
    " 'Guangxi':'桂',\n",
    " 'Guizhou':'贵',\n",
    " 'Hainan':'琼',\n",
    " 'Hebei':'冀',\n",
    " 'Heilongjiang':'黑',\n",
    " 'Henan':'豫',\n",
    " 'Hubei':'鄂',\n",
    " 'Hunan':'湘',\n",
    " 'InnerMongolia':'蒙',\n",
    " 'Jiangsu':'苏',\n",
    " 'Jiangxi':'赣',\n",
    " 'Jilin':'吉',\n",
    " 'Liaoning':'辽',\n",
    " 'Ningxia':'宁',\n",
    " 'Qinghai':'青',\n",
    " 'Shaanxi':'陕',\n",
    " 'Shandong':'鲁',\n",
    " 'Shanghai':'沪',\n",
    " 'Shanxi':'晋',\n",
    " 'Sichuan':'川',\n",
    " 'Tianjin':'津',\n",
    " 'Tibet':'藏',\n",
    " 'Xinjiang':'新',\n",
    " 'Yunnan':'云',\n",
    " 'Zhejiang':'浙',\n",
    " 'police':'警'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'C:\\Users\\Raymond\\PycharmProjects\\tensorflow2.0\\datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_provinces = []\n",
    "all_provinces+=provinces\n",
    "# all_chars+=alphabets\n",
    "# all_chars+=ads\n",
    "all_provinces = list(set(all_provinces))\n",
    "all_provinces.sort()\n",
    "\n",
    "# all_chars.insert(69,'[sep]')\n",
    "\n",
    "provinces2int = {}\n",
    "for i,key in enumerate(all_provinces):\n",
    "    provinces2int[key] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(provinces2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = []\n",
    "# all_chars+=provinces\n",
    "all_chars+=alphabets\n",
    "all_chars+=ads\n",
    "all_chars = list(set(all_chars))\n",
    "all_chars.sort()\n",
    "\n",
    "all_chars.insert(37,'[sep]')\n",
    "\n",
    "char2int = {}\n",
    "for i,key in enumerate(all_chars):\n",
    "    char2int[key] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " 'A': 10,\n",
       " 'B': 11,\n",
       " 'C': 12,\n",
       " 'D': 13,\n",
       " 'E': 14,\n",
       " 'F': 15,\n",
       " 'G': 16,\n",
       " 'H': 17,\n",
       " 'I': 18,\n",
       " 'J': 19,\n",
       " 'K': 20,\n",
       " 'L': 21,\n",
       " 'M': 22,\n",
       " 'N': 23,\n",
       " 'O': 24,\n",
       " 'P': 25,\n",
       " 'Q': 26,\n",
       " 'R': 27,\n",
       " 'S': 28,\n",
       " 'T': 29,\n",
       " 'U': 30,\n",
       " 'V': 31,\n",
       " 'W': 32,\n",
       " 'X': 33,\n",
       " 'Y': 34,\n",
       " 'Z': 35,\n",
       " '[sep]': 36}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['O', '云', '京', '冀', '吉', '学', '宁', '川', '新', '晋', '桂', '沪', '津', '浙', '渝', '湘', '琼', '甘', '皖', '粤', '苏', '蒙', '藏', '警', '豫', '贵', '赣', '辽', '鄂', '闽', '陕', '青', '鲁', '黑'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provinces2int.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[sep]'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "charlist = list(char2int.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raymond\\PycharmProjects\\tensorflow2.0\\datasets\\small_new_energy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raymond\\Anaconda3\\envs\\tf23\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raymond\\PycharmProjects\\tensorflow2.0\\datasets\\CCPD2019\n",
      "C:\\Users\\Raymond\\PycharmProjects\\tensorflow2.0\\datasets\\Synthetic_Chinese_License_Plates\n",
      "(278086, 4) (186317, 4) (91769, 4)\n"
     ]
    }
   ],
   "source": [
    "# lll=[]\n",
    "def get_synthetic_np():\n",
    "    data_root = os.path.join(dataset_path,'Synthetic_Chinese_License_Plates')\n",
    "    data_root = pathlib.Path(data_root)\n",
    "    print(data_root)\n",
    "    annotation = os.path.join(data_root,'annotation')\n",
    "    with open(annotation) as f:\n",
    "        datas = f.readlines()\n",
    "    p = re.compile(\"[<|>]\")\n",
    "    data_gen = {}\n",
    "    for d in datas:\n",
    "        path,plate = d.split()\n",
    "        path = os.path.join(data_root,path)\n",
    "        path = pathlib.Path(path)\n",
    "        split_plate = p.split(plate)\n",
    "        wj,province,num = split_plate[0:3]\n",
    "        try:\n",
    "            police = split_plate[3]\n",
    "            police = pinyin2char[police]\n",
    "        except:\n",
    "            police = ''\n",
    "        if wj or police:\n",
    "            continue\n",
    "        province_label = pinyin2char[province]\n",
    "        province_label = provinces2int[province_label]\n",
    "#         str_plate = ''.join([wj,pinyin2char[province],num,police])\n",
    "        char_label = [char2int[i] for i in num]\n",
    "#         if len(label) == 6:\n",
    "#             print(str_plate)\n",
    "#         lll.append(len(label))\n",
    "        paddings_len = 7 - len(char_label)\n",
    "        for i in range(paddings_len):\n",
    "            char_label.append(36)\n",
    "#         province_label = np.asarray(province_label)\n",
    "        char_label = np.asarray(char_label)\n",
    "        \n",
    "        cor = np.asarray([0,0,94,24])\n",
    "        cor = np.expand_dims(cor,axis=0)\n",
    "        try:\n",
    "            data_gen[province_label].append([str(path),province_label,char_label,cor])\n",
    "        except:\n",
    "            data_gen[province_label] = []\n",
    "            data_gen[province_label].append([str(path),province_label,char_label,cor])\n",
    "\n",
    "    res_data_gen = []\n",
    "    for i in data_gen.keys():\n",
    "        res_pos_features = np.asarray(data_gen[i])\n",
    "        res_data_gen.append(res_pos_features)\n",
    "\n",
    "    data_np = np.concatenate(res_data_gen)\n",
    "    return data_np\n",
    "\n",
    "def get_gen_np():\n",
    "    #生成车牌数据集\n",
    "    p2 = re.compile(\"[_|.]\")\n",
    "    data_root_gen = os.path.join(dataset_path,'small_new_energy')\n",
    "    data_root_gen = pathlib.Path(data_root_gen)\n",
    "    print(data_root_gen)\n",
    "\n",
    "    # 生成车牌数据集\n",
    "    data_gen = {}\n",
    "    for file in data_root_gen.glob('*.jpg'):\n",
    "        # 转换为车牌字符串\n",
    "        str_plate = p2.split(file.parts[-1])[1]\n",
    "        province_label = provinces2int[str_plate[0]]\n",
    "        char_label = [char2int[i] for i in str_plate[1:]]\n",
    "#         label = [char2int[i] for i in str_plate[1]]\n",
    "        if file.parts[-2] == 'small_new_energy':\n",
    "            width = 246\n",
    "        else:\n",
    "            width = 226\n",
    "            char_label.append(36)\n",
    "        char_label = np.asarray(char_label)\n",
    "        \n",
    "        cor = np.asarray([0,0,width,72])\n",
    "        cor = np.expand_dims(cor,axis=0)\n",
    "\n",
    "        \n",
    "\n",
    "        try:\n",
    "#             data_gen[label[0]].append([str(file),label,cor])\n",
    "            data_gen[province_label].append([str(file),province_label,char_label,cor])\n",
    "        except:\n",
    "            data_gen[province_label] = []\n",
    "#             data_gen[label[0]].append([str(file),label,cor])\n",
    "            data_gen[province_label].append([str(file),province_label,char_label,cor])\n",
    "\n",
    "    res_data_gen = []\n",
    "    for i in data_gen.keys():\n",
    "        res_pos_features = np.asarray(data_gen[i])\n",
    "        res_data_gen.append(res_pos_features)\n",
    "\n",
    "\n",
    "    data_np = np.concatenate(res_data_gen)\n",
    "    return data_np\n",
    "\n",
    "def get_ccpd_np():\n",
    "    p = re.compile(\"[_|&]\")\n",
    "    data_root = os.path.join(dataset_path,'CCPD2019')\n",
    "    data_root = pathlib.Path(data_root)\n",
    "    print(data_root)\n",
    "\n",
    "    #resample的数据集\n",
    "    data = {}\n",
    "    for file in data_root.glob('*/*.jpg'):\n",
    "        if file.parts[-2] not in ['ccpd_base','ccpd_green']:\n",
    "            continue\n",
    "        try:\n",
    "            cor = p.split(file.parts[-1].split('-')[2])\n",
    "        except:\n",
    "            continue\n",
    "        cor = [int(i) for i in cor]\n",
    "        cor[0],cor[1] = max(0,cor[0]-random.randint(0,30)),max(0,cor[1]-random.randint(0,30))\n",
    "        cor[2],cor[3] = min(720,cor[2]+random.randint(0,30)),min(1160,cor[3]+random.randint(0,30))\n",
    "        cor = np.asarray([cor[0],cor[1],cor[2],cor[3]])\n",
    "        cor = np.expand_dims(cor,axis=0)\n",
    "\n",
    "        str_plate = file.parts[-1].split('-')[-3].split('_')\n",
    "        int_plate = [int(i) for i in str_plate]\n",
    "        # 转换为车牌字符串\n",
    "        str_plate = [provinces[int_plate[0]],alphabets[int_plate[1]]] + [ads[i] for i in int_plate[2:]]\n",
    "#         label = [char2int[i] for i in str_plate]\n",
    "        province_label = provinces2int[str_plate[0]]\n",
    "        char_label = [char2int[i] for i in str_plate[1:]]\n",
    "        if len(char_label) == 6:\n",
    "            char_label.append(36)\n",
    "        char_label = np.asarray(char_label)\n",
    "\n",
    "        try:\n",
    "#             data[province_label].append([str(file),label,cor])\n",
    "            data[province_label].append([str(file),province_label,char_label,cor])\n",
    "        except:\n",
    "            data[province_label] = []\n",
    "#             data[label[0]].append([str(file),label,cor])\n",
    "            data[province_label].append([str(file),province_label,char_label,cor])\n",
    "\n",
    "    res_data = []\n",
    "    for i in data.keys():\n",
    "        ids = np.arange(len(data[i]))\n",
    "        choices = np.random.choice(ids, 1000)\n",
    "\n",
    "        res_pos_features = np.asarray(data[i])\n",
    "        res_data.append(res_pos_features)\n",
    "\n",
    "\n",
    "    data_np = np.concatenate(res_data)\n",
    "    return data_np\n",
    "\n",
    "gen_np = get_gen_np()\n",
    "ccpd_np = get_ccpd_np()\n",
    "synthetic_np = get_synthetic_np()\n",
    "synthetic_np,_ = train_test_split(synthetic_np,test_size=0.8, shuffle=True)\n",
    "\n",
    "data_np = np.concatenate([gen_np,ccpd_np,synthetic_np])\n",
    "# np.random.shuffle(data_np)\n",
    "train_np,test_np = train_test_split(data_np,test_size=0.33, shuffle=True)\n",
    "print(data_np.shape,train_np.shape,test_np.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211769, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpd_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C:\\\\Users\\\\Raymond\\\\PycharmProjects\\\\tensorflow2.0\\\\datasets\\\\small_new_energy\\\\000000450_宁MFJ2835.jpg',\n",
       "       6, array([22, 15, 19,  2,  8,  3,  5]),\n",
       "       array([[  0,   0, 246,  72]])], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = r'C:\\Users\\Raymond\\PycharmProjects\\tensorflow2.0\\datasets\\CCPD2019\\ccpd_green\\0183796296296-90_95-345&874_742&979-734&979_345&977_346&874_742&876-0_0_3_24_27_29_31_28-90-324.jpg'\n",
    "# img = pathlib.Path(img)\n",
    "# p = re.compile(\"[_|&]\")\n",
    "# cor = p.split(img.parts[-1].split('-')[2])\n",
    "# cor = [int(i) for i in cor]\n",
    "# cor = np.asarray([cor[0],cor[1],cor[2],cor[3]])\n",
    "# img = tf.io.read_file(str(img))\n",
    "# img = tf.io.decode_image(img)\n",
    "# print(img.shape,cor,cor[3]-cor[1],cor[2]-cor[0])\n",
    "# tf.image.crop_to_bounding_box(\n",
    "#         img, cor[1], cor[0], cor[3]-cor[1], cor[2]-cor[0]\n",
    "#         )\n",
    "# # tf.image.crop_to_bounding_box(\n",
    "# #         img, cor[1], cor[0], cor[3]-cor[1], cor[2]-cor[0]\n",
    "# #         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen():\n",
    "    for file,province_label,char_label,cor in train_np:\n",
    "        yield str(file),province_label,char_label,cor\n",
    "def val_gen():\n",
    "    for file,province_label,char_label,cor in test_np:\n",
    "        yield str(file),province_label,char_label,cor\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(train_gen,(tf.string,tf.int32,tf.int32,tf.int32))\n",
    "val_ds = tf.data.Dataset.from_generator(val_gen,(tf.string,tf.int32,tf.int32,tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(lll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12600, 4), (211769, 4), (53717, 4), (278086, 4))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_np.shape,ccpd_np.shape,synthetic_np.shape,data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 100000\n",
    "REPEAT = 6\n",
    "DATA_SIZE = train_np.shape[0]\n",
    "TRAIN_SIZE = (DATA_SIZE- VAL_SIZE) * REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache(\"train_cache\")\n",
    "val_ds = val_ds.cache(\"val_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tf.io.gfile.exists('train_cache.index'):\n",
    "    for _ in tqdm(train_ds.as_numpy_iterator()):\n",
    "        pass\n",
    "if not tf.io.gfile.exists('val_cache.index'):\n",
    "    for _ in tqdm(val_ds.as_numpy_iterator()):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p,_,_ in train_ds.as_numpy_iterator():\n",
    "#     try:\n",
    "#         img = tf.io.read_file(p)\n",
    "#         img = tf.io.decode_image(img)\n",
    "#     except:\n",
    "#         print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(path,province_label,char_label,cor):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img)\n",
    "#     img = tf.image.rgb_to_grayscale(img)\n",
    "    img = tf.image.convert_image_dtype(img,tf.float32)\n",
    "    cor = cor[0]\n",
    "    img = tf.image.crop_to_bounding_box(\n",
    "        img, cor[1], cor[0], cor[3]-cor[1], cor[2]-cor[0]\n",
    "        )\n",
    "#     img = tf.image.resize(img,[65,210])\n",
    "#     img = tf.image.random_crop(img,[60,200,3])\n",
    "    img = tf.image.resize(img,[64,224])\n",
    "#     img = tf.transpose(img, perm=[1, 0, 2])\n",
    "\n",
    "    return img,(province_label,char_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'C:\\\\Users\\\\Raymond\\\\PycharmProjects\\\\tensorflow2.0\\\\datasets\\\\CCPD2019\\\\ccpd_base\\\\0316810344828-89_95-162&600_466&700-492&690_158&715_164&605_498&580-0_0_10_25_23_29_32-133-45.jpg',\n",
       " 18,\n",
       " array([10, 21,  1, 35,  5,  8, 36]),\n",
       " array([[139, 598, 494, 726]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,l,c in tqdm(train_ds.as_numpy_iterator()):\n",
    "#     img = tf.io.read_file(i)\n",
    "#     img = tf.io.decode_image(img)\n",
    "# #     tf.print(img.shape)\n",
    "#     cor = c[0]\n",
    "#     h,w,_ = img.shape\n",
    "#     try:\n",
    "#         img = tf.image.crop_to_bounding_box(\n",
    "#         img, cor[1], cor[0], cor[3]-cor[1], cor[2]-cor[0]\n",
    "#         )\n",
    "#     except:\n",
    "#         print(i)\n",
    "# #     if h<(c[3]-c[1]) or w<c[2]-c[0]:\n",
    "# #         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(1000,reshuffle_each_iteration=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "train_ds = train_ds.map(postprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.map(postprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in tqdm(train_ds.as_numpy_iterator()):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def postprocess(img,label,cor):\n",
    "#     img = tf.io.read_file(path)\n",
    "#     img = tf.io.decode_image(img)\n",
    "#     img = tf.image.convert_image_dtype(img,tf.float32)\n",
    "#     cor = cor[0]\n",
    "#     img = tf.image.crop_to_bounding_box(\n",
    "#         img, cor[1], cor[0], cor[3]-cor[1], cor[2]-cor[0]\n",
    "#         )\n",
    "#     img = tf.image.resize(img,[65,210])\n",
    "#     img = tf.image.random_crop(img,[60,200,3])\n",
    "#     img = tf.transpose(img, perm=[1, 0, 2])\n",
    "\n",
    "#     return img,label\n",
    "\n",
    "# def map_fn(img, label,cor):\n",
    "#   # py_func doesn't set the shape of the returned tensors.\n",
    "#   img,label = tf.py_function(postprocess, \n",
    "#                                        inp=[img, label,cor], \n",
    "#                                        Tout=(tf.float32, tf.int32))\n",
    "\n",
    "#   # `tf.data.Datasets` work best if all components have a shape set\n",
    "#   #  so set the shapes manually: \n",
    "#   img.set_shape([200,60,3])\n",
    "#   label.set_shape([None])\n",
    "\n",
    "#   return img,label\n",
    "\n",
    "\n",
    "# train_ds = train_ds.map(map_fn,num_parallel_calls=tf.data.experimental.AUTOTUNE).repeat(3)\n",
    "# val_ds = val_ds.map(map_fn,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# test_ds = test_ds.map(map_fn,num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_test,_,_ = postprocess(p,l,c)\n",
    "# image_test = tf.image.resize(image_test,[30,100])\n",
    "# # print(image_test)\n",
    "\n",
    "# plt.imshow(image_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd5 in position 222: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2606\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2607\u001b[1;33m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   2608\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 222: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-425d1a7511f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtests\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3783\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2103\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2105\u001b[1;33m       \u001b[0mexecutor_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\eager\\executor.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd5 in position 222: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "tests,labels = next(train_ds.unbatch().shuffle(30).as_numpy_iterator())\n",
    "plt.imshow(tests)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tests,labels = next(train_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tests.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwDarknetConv(x, filters, size, strides=1, batch_norm=True,bias_initializer=tf.keras.initializers.Zeros()):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "#                kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "#                bias_initializer=bias_initializer,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Add,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LeakyReLU,\n",
    "    MaxPool2D,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwYoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = dwDarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        x = dwDarknetConv(x, filters, 1)\n",
    "        x = dwDarknetConv(x, filters * 2, 3)\n",
    "        x = dwDarknetConv(x, filters, 1)\n",
    "#         x = dwDarknetConv(x, filters * 2, 3)\n",
    "#         x = dwDarknetConv(x, filters, 1)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv\n",
    "\n",
    "def dwDarknetTiny(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = dwDarknetConv(x, 16, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = dwDarknetConv(x, 32, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = dwDarknetConv(x, 64, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = dwDarknetConv(x, 128, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = x_8 = dwDarknetConv(x, 256, 3)  # skip connection\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = dwDarknetConv(x, 512, 3)\n",
    "    x = MaxPool2D(2, 1, 'same')(x)\n",
    "    x = dwDarknetConv(x, 1024, 3)\n",
    "    return tf.keras.Model(inputs, (x_8, x), name=name)\n",
    "\n",
    "def dwYoloV3Tiny(size=None):\n",
    "    x = inputs = Input([64, 224, 3])\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.transpose(x,[0,2,1,3]))(x)\n",
    "\n",
    "    x_8, x = dwDarknetTiny(name='yolo_darknet')(x)\n",
    "    output_0 = tf.keras.layers.Flatten()(x)\n",
    "    output_0 = tf.keras.layers.Dense(34)(output_0)\n",
    "    output_0 = tf.keras.layers.Activation('softmax')(output_0)\n",
    "\n",
    "    x = dwYoloConv(256, name='yolo_conv_0')(x)\n",
    "    x = dwYoloConv(128, name='yolo_conv_1')((x, x_8))\n",
    "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "    output_1 = tf.keras.layers.Conv1D(128,3)(x)\n",
    "    output_1 = tf.keras.layers.LeakyReLU(alpha=0.1)(output_1)\n",
    "    output_1 = tf.keras.layers.Dense(37)(output_1)\n",
    "    output_1 = tf.keras.layers.Activation('softmax')(output_1)\n",
    "\n",
    "    return tf.keras.Model(inputs, (output_0,output_1), name='yolov3_tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 0.3186 - val_loss: 0.3178 - acc: 0.92 - Total params: 131,744\n",
    "# def dwDarknetConv(x, filters, size, strides=1, batch_norm=True,bias_initializer=tf.keras.initializers.Zeros()):\n",
    "#     if strides == 1:\n",
    "#         padding = 'same'\n",
    "#     else:\n",
    "#         x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "#         padding = 'valid'\n",
    "#     x = tf.keras.layers.SeparableConv2D(filters=filters, kernel_size=size,\n",
    "#                strides=strides, padding=padding,\n",
    "# #                kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01),\n",
    "# #                bias_initializer=bias_initializer,\n",
    "#                use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "#     if batch_norm:\n",
    "#         x = tf.keras.layers.BatchNormalization()(x)\n",
    "#         x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     return x\n",
    "\n",
    "def conv1d_model():\n",
    "    inp = tf.keras.Input(shape=(64,224,3),dtype=tf.float32,name=\"input\")\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.transpose(x,[0,2,1,3]))(inp)\n",
    "    features_1 = dwDarknetConv(x,32,3,strides=2)\n",
    "    \n",
    "    features_2 = dwDarknetConv(features_1,32,3)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_2 = dwDarknetConv(features_2,32,3,strides=2)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_2 = dwDarknetConv(features_2,64,3)\n",
    "\n",
    "    features_3 = dwDarknetConv(features_2,64,3,strides=2)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_3 = dwDarknetConv(features_3,64,3)\n",
    "  \n",
    "    features_4 = dwDarknetConv(features_3,64,3,strides=1)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_4 = dwDarknetConv(features_4,64,3)\n",
    "#     out = tf.keras.layers.concatenate([features_4,features_3,features_2], axis=-1)\n",
    "    out = dwDarknetConv(features_4,128,3,strides=2)\n",
    "    output_0 = dwDarknetConv(out,128,3,strides=2)\n",
    "    output_0 = tf.keras.layers.Flatten()(output_0)\n",
    "    output_0 = tf.keras.layers.Dense(34,kernel_regularizer=l2(0.0005))(output_0)\n",
    "    output_0 = tf.keras.layers.Activation('softmax',name='output_0')(output_0)\n",
    "    \n",
    "    output_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(out)\n",
    "    output_1 = tf.keras.layers.ZeroPadding1D(1)(output_1)\n",
    "    output_1 = tf.keras.layers.Conv1D(128,3,activation='relu')(output_1)\n",
    "    \n",
    "    output_1 = tf.keras.layers.ZeroPadding1D(1)(output_1)\n",
    "    output_1 = tf.keras.layers.Conv1D(128,3,activation='relu')(output_1)\n",
    "    output_1 = tf.keras.layers.ZeroPadding1D(1)(output_1)\n",
    "    output_1 = tf.keras.layers.Conv1D(128,3,activation='relu')(output_1)\n",
    "    \n",
    "    output_1 = tf.keras.layers.ZeroPadding1D(1)(output_1)\n",
    "    output_1 = tf.keras.layers.Conv1D(64,3)(output_1)\n",
    "    output_1 = tf.keras.layers.Dense(37)(output_1)\n",
    "    output_1 = tf.keras.layers.Activation('softmax',name='output_1')(output_1)\n",
    "\n",
    "    return tf.keras.Model(inp, (output_0,output_1), name='cnn_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv1d_model():\n",
    "#     inp = tf.keras.Input(shape=(64,224,3),dtype=tf.float32,name=\"input\")\n",
    "#     x = tf.keras.layers.Lambda(lambda x: tf.transpose(x,[0,2,1,3]))(inp)\n",
    "#     features_1 = dwDarknetConv(x,32,3,strides=2)\n",
    "    \n",
    "#     features_2 = dwDarknetConv(features_1,32,3)\n",
    "\n",
    "#     for _ in range(1):\n",
    "#         features_2 = dwDarknetConv(features_2,32,3,strides=2)\n",
    "\n",
    "#     for _ in range(1):\n",
    "#         features_2 = dwDarknetConv(features_2,64,3)\n",
    "\n",
    "#     features_3 = dwDarknetConv(features_2,64,3,strides=2)\n",
    "\n",
    "#     for _ in range(1):\n",
    "#         features_3 = dwDarknetConv(features_3,64,3)\n",
    "  \n",
    "#     features_4 = dwDarknetConv(features_3,64,3,strides=1)\n",
    "\n",
    "#     for _ in range(1):\n",
    "#         features_4 = dwDarknetConv(features_4,64,3)\n",
    "# #     out = tf.keras.layers.concatenate([features_4,features_3,features_2], axis=-1)\n",
    "#     out = dwDarknetConv(features_4,128,3,strides=2)\n",
    "# #     output_0 = dwDarknetConv(out,64,3,strides=2)\n",
    "# #     output_0 = tf.keras.layers.Flatten()(output_0)\n",
    "# #     output_0 = tf.keras.layers.Dense(34)(output_0)\n",
    "# #     output_0 = tf.keras.layers.Activation('softmax',name='output_0')(output_0)\n",
    "    \n",
    "#     out = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(out)\n",
    "#     out = tf.keras.layers.ZeroPadding1D(1)(out)\n",
    "#     out = tf.keras.layers.Conv1D(128,3,activation='relu')(out)\n",
    "    \n",
    "#     out = tf.keras.layers.ZeroPadding1D(1)(out)\n",
    "#     out = tf.keras.layers.Conv1D(128,3,activation='relu')(out)\n",
    "#     out = tf.keras.layers.ZeroPadding1D(1)(out)\n",
    "#     out = tf.keras.layers.Conv1D(128,3,activation='relu')(out)\n",
    "    \n",
    "#     out = tf.keras.layers.ZeroPadding1D(1)(out)\n",
    "#     out = tf.keras.layers.Conv1D(64,3)(out)\n",
    "    \n",
    "#     output_0 = tf.keras.layers.Flatten()(out)\n",
    "#     output_0 = tf.keras.layers.Dense(34)(output_0)\n",
    "#     output_0 = tf.keras.layers.Activation('softmax',name='output_0')(output_0)\n",
    "    \n",
    "#     output_1 = tf.keras.layers.Dense(37)(out)\n",
    "#     output_1 = tf.keras.layers.Activation('softmax',name='output_1')(output_1)\n",
    "\n",
    "#     return tf.keras.Model(inp, (output_0,output_1), name='cnn_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crnn_model(filter_size = 32):\n",
    "    inp = tf.keras.Input(shape=(64,224,3),dtype=tf.float32,name=\"input\")\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.transpose(x,[0,2,1,3]))(inp)\n",
    "    features_1 = dwDarknetConv(x,filter_size,3,strides=2)\n",
    "    \n",
    "    features_2 = dwDarknetConv(features_1,filter_size,3)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_2 = dwDarknetConv(features_2,filter_size,3,strides=2)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_2 = dwDarknetConv(features_2,filter_size*2,3)\n",
    "\n",
    "    features_3 = dwDarknetConv(features_2,filter_size*2,3,strides=2)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_3 = dwDarknetConv(features_3,filter_size*2,3)\n",
    "  \n",
    "    features_4 = dwDarknetConv(features_3,filter_size*2,3,strides=1)\n",
    "\n",
    "    for _ in range(1):\n",
    "        features_4 = dwDarknetConv(features_4,filter_size*2,3)\n",
    "#     out = tf.keras.layers.concatenate([features_4,features_3,features_2], axis=-1)\n",
    "    out = dwDarknetConv(features_4,filter_size*4,3,strides=2)\n",
    "    output_0 = dwDarknetConv(out,filter_size*2,3,strides=2)\n",
    "    output_0 = tf.keras.layers.Flatten()(output_0)\n",
    "    output_0 = tf.keras.layers.Dense(34)(output_0)\n",
    "    output_0 = tf.keras.layers.Activation('softmax',name='output_0')(output_0)\n",
    "    \n",
    "    output_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(out)\n",
    "    output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(filter_size*4, return_sequences=True,stateful=False,dropout=0.1))(output_1)\n",
    "    output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(filter_size*2, return_sequences=True,stateful=False,dropout=0.1))(output_1)\n",
    "    output_1 = tf.keras.layers.Dense(37,activation='softmax')(output_1)\n",
    "\n",
    "    return tf.keras.Model(inp, (output_0,output_1), name='cnn_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = dwYoloV3Tiny()\n",
    "cnn_model = conv1d_model()\n",
    "# cnn_model = crnn_model(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = tf.keras.Input(shape=(200,60,3),dtype=tf.float32,name=\"input\")\n",
    "# out = dwDarknetConv(inp, 32, 3)\n",
    "# # out = tf.keras.layers.SeparableConv2D(32, (3, 3), activation='relu', padding=\"same\", kernel_initializer=\"he_normal\")(inp)\n",
    "# # out = tf.keras.layers.BatchNormalization()(out)\n",
    "# out = tf.keras.layers.MaxPooling2D((2, 2))(out)\n",
    "# out = dwDarknetConv(out, 64, 3)\n",
    "# # out = tf.keras.layers.SeparableConv2D(64, (3, 3), activation='relu', padding=\"same\", kernel_initializer=\"he_normal\")(out)\n",
    "# # out = tf.keras.layers.BatchNormalization()(out)\n",
    "# out = tf.keras.layers.MaxPooling2D((2, 2))(out)\n",
    "# out = dwDarknetConv(out, 128, 3,batch_norm=False)\n",
    "# out = dwDarknetConv(out, 64, 3,batch_norm=False)\n",
    "# out = tf.keras.layers.Conv2D(64,(1,1))(out)\n",
    "# out = tf.keras.layers.BatchNormalization()(out)\n",
    "# out = tf.keras.layers.LeakyReLU(alpha=0.1)(out)\n",
    "# out = tf.keras.layers.Flatten()(out)\n",
    "\n",
    "# # out = tf.keras.layers.SeparableConv2D(256, (3, 3), activation='relu')(out)\n",
    "# # out = tf.keras.layers.BatchNormalization()(out)\n",
    "\n",
    "# # out = tf.keras.layers.Lambda(lambda x: tf.transpose(x,[0,2,1,3]))(out)\n",
    "\n",
    "# # out = tf.keras.layers.Dense(15*70)(out)\n",
    "# # out = tf.keras.layers.LeakyReLU(alpha=0.1)(out)\n",
    "# out = tf.keras.layers.Reshape(( 15, -1))(out)\n",
    "# out = tf.keras.layers.Dense(70)(out)\n",
    "# out = tf.keras.layers.Activation('softmax')(out)\n",
    "# # out = tf.keras.layers.Dropout(0.2)(out)\n",
    "# cnn_model = tf.keras.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_out = cnn_model(img_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_out = cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].shape,labels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones([BATCH_SIZE],dtype=\"int32\") * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接收logits\n",
    "def loss(y_true, y_pred):\n",
    "    batch_size = tf.cast(tf.shape(y_pred)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "    input_length = input_length * tf.ones(shape=(batch_size), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_size), dtype=\"int64\")\n",
    "    y_pred = tf.math.log(y_pred + tf.keras.backend.epsilon())\n",
    "    loss_ = tf.nn.ctc_loss(labels=y_true,\n",
    "                           logits=y_pred,\n",
    "                           label_length=label_length,\n",
    "                           logit_length=input_length,\n",
    "                           logits_time_major = False)\n",
    "    return tf.expand_dims(loss_,axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接收softmax\n",
    "def loss2(y_true, y_pred):\n",
    "    batch_size = tf.cast(tf.shape(y_pred)[0], dtype=\"int32\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int32\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int32\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_size, 1), dtype=\"int32\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_size, 1), dtype=\"int32\")\n",
    "    loss_ = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    \n",
    "    return loss_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(y_true, y_pred):\n",
    "    true_provinces_labels,true_char_labels = y_true\n",
    "    pred_provinces_labels,pred_char_labels = y_pred\n",
    "    ctc_loss = loss2(true_char_labels,pred_char_labels)\n",
    "    cls_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "    true_provinces_labels, pred_provinces_labels, from_logits=False, axis=-1)\n",
    "    cls_loss = tf.expand_dims(cls_loss,axis=-1)\n",
    "#     return tf.reduce_sum(ctc_loss,cls_loss)\n",
    "    return ctc_loss+cls_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_loss2 = [tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                 loss2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_loss(labels,rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss(labels,rnn_out),loss2(labels,rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('weights/rgb_plate_weights/weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=opt, loss=combined_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6,verbose=1),\n",
    "            EarlyStopping(patience=5,restore_best_weights=True,verbose=1),\n",
    "#             ModelCheckpoint('checkpoints/yolov3_train_{epoch}.tf',\n",
    "#                             verbose=1, save_weights_only=True),\n",
    "            tf.keras.callbacks.TerminateOnNaN()\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "STEPS_PER_EPOCH = TRAIN_SIZE//(EPOCHS*BATCH_SIZE)\n",
    "VAL_STEPS = VAL_SIZE // (EPOCHS*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 78)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEPS_PER_EPOCH,VAL_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "404/404 [==============================] - 44s 110ms/step - loss: 20.6041 - output_0_loss: 1.1443 - output_1_loss: 19.4103 - val_loss: 27.4727 - val_output_0_loss: 3.3320 - val_output_1_loss: 24.0649\n",
      "Epoch 2/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 13.6303 - output_0_loss: 1.0035 - output_1_loss: 12.5141 - val_loss: 10.8878 - val_output_0_loss: 0.9760 - val_output_1_loss: 9.7562\n",
      "Epoch 3/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 6.8288 - output_0_loss: 0.8522 - output_1_loss: 5.7696 - val_loss: 5.3375 - val_output_0_loss: 0.7790 - val_output_1_loss: 4.3006\n",
      "Epoch 4/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 4.2738 - output_0_loss: 0.6701 - output_1_loss: 3.2956 - val_loss: 4.4670 - val_output_0_loss: 0.6234 - val_output_1_loss: 3.4891\n",
      "Epoch 5/40\n",
      "404/404 [==============================] - 43s 106ms/step - loss: 3.2626 - output_0_loss: 0.5785 - output_1_loss: 2.2889 - val_loss: 3.1678 - val_output_0_loss: 0.5353 - val_output_1_loss: 2.2062\n",
      "Epoch 6/40\n",
      "404/404 [==============================] - 45s 110ms/step - loss: 2.7258 - output_0_loss: 0.4905 - output_1_loss: 1.7845 - val_loss: 2.8099 - val_output_0_loss: 0.6428 - val_output_1_loss: 1.6960\n",
      "Epoch 7/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 2.4477 - output_0_loss: 0.4640 - output_1_loss: 1.4927 - val_loss: 2.5000 - val_output_0_loss: 0.4251 - val_output_1_loss: 1.5708\n",
      "Epoch 8/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 2.1610 - output_0_loss: 0.4089 - output_1_loss: 1.2451 - val_loss: 2.4303 - val_output_0_loss: 0.4072 - val_output_1_loss: 1.5123\n",
      "Epoch 9/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 2.0349 - output_0_loss: 0.3805 - output_1_loss: 1.1365 - val_loss: 1.9676 - val_output_0_loss: 0.3655 - val_output_1_loss: 1.0826\n",
      "Epoch 10/40\n",
      "404/404 [==============================] - 43s 105ms/step - loss: 1.8667 - output_0_loss: 0.3552 - output_1_loss: 0.9928 - val_loss: 2.2982 - val_output_0_loss: 0.3422 - val_output_1_loss: 1.4380\n",
      "Epoch 11/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 1.7311 - output_0_loss: 0.3112 - output_1_loss: 0.9120 - val_loss: 1.8662 - val_output_0_loss: 0.4251 - val_output_1_loss: 0.9419\n",
      "Epoch 12/40\n",
      "404/404 [==============================] - 43s 108ms/step - loss: 1.6606 - output_0_loss: 0.3151 - output_1_loss: 0.8534 - val_loss: 1.7034 - val_output_0_loss: 0.2878 - val_output_1_loss: 0.9322\n",
      "Epoch 13/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 1.5932 - output_0_loss: 0.2932 - output_1_loss: 0.8232 - val_loss: 1.5438 - val_output_0_loss: 0.2861 - val_output_1_loss: 0.7858\n",
      "Epoch 14/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 1.4249 - output_0_loss: 0.2743 - output_1_loss: 0.6892 - val_loss: 1.8746 - val_output_0_loss: 0.3093 - val_output_1_loss: 1.1155\n",
      "Epoch 15/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 1.3819 - output_0_loss: 0.2673 - output_1_loss: 0.6725 - val_loss: 1.5266 - val_output_0_loss: 0.2733 - val_output_1_loss: 0.8165\n",
      "Epoch 16/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 1.3450 - output_0_loss: 0.2598 - output_1_loss: 0.6521 - val_loss: 1.5280 - val_output_0_loss: 0.2559 - val_output_1_loss: 0.8426\n",
      "Epoch 17/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 1.3205 - output_0_loss: 0.2522 - output_1_loss: 0.6427 - val_loss: 1.3162 - val_output_0_loss: 0.2503 - val_output_1_loss: 0.6442\n",
      "Epoch 18/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 1.2518 - output_0_loss: 0.2447 - output_1_loss: 0.5927 - val_loss: 1.5316 - val_output_0_loss: 0.3041 - val_output_1_loss: 0.8181\n",
      "Epoch 19/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 1.1925 - output_0_loss: 0.2293 - output_1_loss: 0.5609 - val_loss: 1.1890 - val_output_0_loss: 0.2257 - val_output_1_loss: 0.5639\n",
      "Epoch 20/40\n",
      "404/404 [==============================] - 45s 110ms/step - loss: 1.1396 - output_0_loss: 0.2114 - output_1_loss: 0.5400 - val_loss: 1.3686 - val_output_0_loss: 0.2376 - val_output_1_loss: 0.7532\n",
      "Epoch 21/40\n",
      "404/404 [==============================] - ETA: 0s - loss: 1.1210 - output_0_loss: 0.2160 - output_1_loss: 0.5322\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 1.1210 - output_0_loss: 0.2160 - output_1_loss: 0.5322 - val_loss: 1.2070 - val_output_0_loss: 0.2162 - val_output_1_loss: 0.6206\n",
      "Epoch 22/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 0.8683 - output_0_loss: 0.1590 - output_1_loss: 0.3419 - val_loss: 0.9071 - val_output_0_loss: 0.1753 - val_output_1_loss: 0.3668\n",
      "Epoch 23/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 0.8280 - output_0_loss: 0.1589 - output_1_loss: 0.3064 - val_loss: 0.8444 - val_output_0_loss: 0.1661 - val_output_1_loss: 0.3174\n",
      "Epoch 24/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 0.7903 - output_0_loss: 0.1548 - output_1_loss: 0.2767 - val_loss: 0.8118 - val_output_0_loss: 0.1608 - val_output_1_loss: 0.2939\n",
      "Epoch 25/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 0.7614 - output_0_loss: 0.1454 - output_1_loss: 0.2613 - val_loss: 0.8061 - val_output_0_loss: 0.1601 - val_output_1_loss: 0.2940\n",
      "Epoch 26/40\n",
      "404/404 [==============================] - 43s 106ms/step - loss: 0.7572 - output_0_loss: 0.1409 - output_1_loss: 0.2669 - val_loss: 0.7853 - val_output_0_loss: 0.1584 - val_output_1_loss: 0.2796\n",
      "Epoch 27/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 0.7512 - output_0_loss: 0.1394 - output_1_loss: 0.2666 - val_loss: 0.8062 - val_output_0_loss: 0.1601 - val_output_1_loss: 0.3032\n",
      "Epoch 28/40\n",
      "404/404 [==============================] - 42s 105ms/step - loss: 0.7022 - output_0_loss: 0.1354 - output_1_loss: 0.2259 - val_loss: 0.7751 - val_output_0_loss: 0.1523 - val_output_1_loss: 0.2833\n",
      "Epoch 29/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 0.6968 - output_0_loss: 0.1306 - output_1_loss: 0.2283 - val_loss: 0.7758 - val_output_0_loss: 0.1435 - val_output_1_loss: 0.2964\n",
      "Epoch 30/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 0.6799 - output_0_loss: 0.1372 - output_1_loss: 0.2075 - val_loss: 0.7601 - val_output_0_loss: 0.1528 - val_output_1_loss: 0.2728\n",
      "Epoch 31/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 0.6917 - output_0_loss: 0.1282 - output_1_loss: 0.2301 - val_loss: 0.7341 - val_output_0_loss: 0.1461 - val_output_1_loss: 0.2559\n",
      "Epoch 32/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 0.6810 - output_0_loss: 0.1315 - output_1_loss: 0.2182 - val_loss: 0.7611 - val_output_0_loss: 0.1475 - val_output_1_loss: 0.2833\n",
      "Epoch 33/40\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.6574 - output_0_loss: 0.1267 - output_1_loss: 0.2018\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 0.6574 - output_0_loss: 0.1267 - output_1_loss: 0.2018 - val_loss: 0.7562 - val_output_0_loss: 0.1442 - val_output_1_loss: 0.2842\n",
      "Epoch 34/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 0.6348 - output_0_loss: 0.1189 - output_1_loss: 0.1882 - val_loss: 0.7212 - val_output_0_loss: 0.1379 - val_output_1_loss: 0.2561\n",
      "Epoch 35/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 0.5872 - output_0_loss: 0.1073 - output_1_loss: 0.1530 - val_loss: 0.7161 - val_output_0_loss: 0.1367 - val_output_1_loss: 0.2528\n",
      "Epoch 36/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 0.5911 - output_0_loss: 0.1085 - output_1_loss: 0.1564 - val_loss: 0.7024 - val_output_0_loss: 0.1345 - val_output_1_loss: 0.2421\n",
      "Epoch 37/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 0.6169 - output_0_loss: 0.1137 - output_1_loss: 0.1776 - val_loss: 0.6889 - val_output_0_loss: 0.1339 - val_output_1_loss: 0.2297\n",
      "Epoch 38/40\n",
      "404/404 [==============================] - 44s 108ms/step - loss: 0.6282 - output_0_loss: 0.1207 - output_1_loss: 0.1824 - val_loss: 0.6883 - val_output_0_loss: 0.1318 - val_output_1_loss: 0.2316\n",
      "Epoch 39/40\n",
      "404/404 [==============================] - 43s 107ms/step - loss: 0.5974 - output_0_loss: 0.1148 - output_1_loss: 0.1578 - val_loss: 0.6877 - val_output_0_loss: 0.1313 - val_output_1_loss: 0.2317\n",
      "Epoch 40/40\n",
      "404/404 [==============================] - 44s 109ms/step - loss: 0.5870 - output_0_loss: 0.1021 - output_1_loss: 0.1607 - val_loss: 0.6832 - val_output_0_loss: 0.1306 - val_output_1_loss: 0.2287\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_ds.repeat(),validation_data=val_ds,epochs=EPOCHS,callbacks=callbacks,steps_per_epoch=STEPS_PER_EPOCH,validation_steps=VAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'RMSprop/learning_rate:0' shape=() dtype=float32, numpy=4.0000003e-05>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input):\n",
    "    batch_size = tf.cast(tf.shape(input)[0], dtype=\"int32\")\n",
    "    input_length = tf.cast(tf.shape(input)[1], dtype=\"int32\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_size), dtype=\"int32\")\n",
    "    decoded = tf.keras.backend.ctc_decode(input,input_length,greedy=True)\n",
    "#     decoded,_ = tf.nn.ctc_greedy_decoder(\n",
    "#         tf.transpose(input,[1,0,2]), input_length, merge_repeated=True\n",
    "#         )\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.96\n"
     ]
    }
   ],
   "source": [
    "val_img,val_label = next(val_ds.unbatch().batch(3000).as_numpy_iterator())\n",
    "pred_p,pred_c = model.predict(val_img)\n",
    "true_p,true_c = val_label\n",
    "c = 0\n",
    "for i,l in enumerate(decode(pred_c)[0][0].numpy()[:,:7]):\n",
    "    if l[-1] == -1:\n",
    "        if l[:6].tolist() == true_c[i][0:6].tolist():\n",
    "            c+=1\n",
    "    else:\n",
    "        if l.tolist() == true_c[i].tolist():\n",
    "            c+=1\n",
    "print(\"准确率：%4.2f\"%(c/3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('weights/crnn_plate_weights/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('weights/crnn_plate_weights/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('crnn_plate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights/rgb_plate_weights/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: rgb_plate_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('rgb_plate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights/rgb_plate_weights/weights')\n",
    "out = tf.keras.layers.Lambda(lambda x: decode(x))(model.outputs[1])\n",
    "ctc_model = tf.keras.Model(model.inputs, [model.outputs[0],tf.cast(out[0],tf.int8)], name='ctc_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'output_0/Softmax:0' shape=(None, 34) dtype=float32>,\n",
       " <tf.Tensor 'Cast_4:0' shape=(1, None, None) dtype=int8>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3, 34), dtype=float32, numpy=\n",
       " array([[4.9698660e-06, 2.4301248e-06, 2.6165787e-06, 1.0160279e-06,\n",
       "         1.4221424e-06, 4.9822988e-06, 6.9477692e-06, 2.0395055e-05,\n",
       "         3.1504887e-06, 5.2561046e-07, 4.7043604e-06, 9.0076619e-06,\n",
       "         1.0015608e-06, 7.2509829e-07, 2.6370503e-06, 2.0683804e-06,\n",
       "         4.6596028e-06, 9.1511702e-06, 9.9988604e-01, 1.8203883e-06,\n",
       "         1.5120563e-06, 4.9173900e-07, 3.5236585e-06, 4.9727391e-06,\n",
       "         1.6251294e-06, 5.2749658e-07, 9.7861528e-07, 6.2589729e-06,\n",
       "         7.0882851e-07, 1.8597227e-06, 3.4194836e-06, 1.7311625e-06,\n",
       "         1.8513808e-06, 2.7280902e-07],\n",
       "        [4.9698660e-06, 2.4301248e-06, 2.6165787e-06, 1.0160279e-06,\n",
       "         1.4221424e-06, 4.9822988e-06, 6.9477692e-06, 2.0395055e-05,\n",
       "         3.1504887e-06, 5.2561046e-07, 4.7043604e-06, 9.0076619e-06,\n",
       "         1.0015608e-06, 7.2509829e-07, 2.6370503e-06, 2.0683804e-06,\n",
       "         4.6596028e-06, 9.1511702e-06, 9.9988604e-01, 1.8203883e-06,\n",
       "         1.5120563e-06, 4.9173900e-07, 3.5236585e-06, 4.9727391e-06,\n",
       "         1.6251294e-06, 5.2749658e-07, 9.7861528e-07, 6.2589729e-06,\n",
       "         7.0882851e-07, 1.8597227e-06, 3.4194836e-06, 1.7311625e-06,\n",
       "         1.8513808e-06, 2.7280902e-07],\n",
       "        [4.9698660e-06, 2.4301248e-06, 2.6165787e-06, 1.0160279e-06,\n",
       "         1.4221424e-06, 4.9822988e-06, 6.9477692e-06, 2.0395055e-05,\n",
       "         3.1504887e-06, 5.2561046e-07, 4.7043604e-06, 9.0076619e-06,\n",
       "         1.0015608e-06, 7.2509829e-07, 2.6370503e-06, 2.0683804e-06,\n",
       "         4.6596028e-06, 9.1511702e-06, 9.9988604e-01, 1.8203883e-06,\n",
       "         1.5120563e-06, 4.9173900e-07, 3.5236585e-06, 4.9727391e-06,\n",
       "         1.6251294e-06, 5.2749658e-07, 9.7861528e-07, 6.2589729e-06,\n",
       "         7.0882851e-07, 1.8597227e-06, 3.4194836e-06, 1.7311625e-06,\n",
       "         1.8513808e-06, 2.7280902e-07]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 3, 14), dtype=int8, numpy=\n",
       " array([[[10, 13, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [10, 13, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         [10, 13, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]],\n",
       "       dtype=int8)>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_model(tf.ones((3,64,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Raymond\\AppData\\Local\\Temp\\tmpu9xqk1y7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Raymond\\AppData\\Local\\Temp\\tmpu9xqk1y7\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(ctc_model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1762488"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = tflite_models_dir/\"model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Raymond\\AppData\\Local\\Temp\\tmpwa1rgao1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Raymond\\AppData\\Local\\Temp\\tmpwa1rgao1\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "477872"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_quant_file = tflite_models_dir/\"model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'input',\n",
       "  'index': 0,\n",
       "  'shape': array([  1,  64, 224,   3]),\n",
       "  'shape_signature': array([ -1,  64, 224,   3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Identity',\n",
       "  'index': 133,\n",
       "  'shape': array([ 1, 34]),\n",
       "  'shape_signature': array([-1, 34]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity_1',\n",
       "  'index': 126,\n",
       "  'shape': array([ 1,  1, 37]),\n",
       "  'shape_signature': array([-1, -1, 37]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
    "interpreter_quant.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_0_index = interpreter.get_output_details()[0][\"index\"]\n",
    "  output_1_index = interpreter.get_output_details()[1][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  prediction_chars = []\n",
    "  for test_image,test_label in val_ds.unbatch().take(3000).as_numpy_iterator():\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    pred_p = interpreter.get_tensor(output_0_index)\n",
    "    pred_c = interpreter.get_tensor(output_1_index)\n",
    "    digit = np.argmax(pred_p[0])\n",
    "    prediction_digits.append(digit)\n",
    "    prediction_chars.append(decode(pred_c)[0][0][0].numpy()[:7])\n",
    "#     tf.print(decode(pred_c())[0][0][0].numpy()[:7])\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  _,test_labels = next(val_ds.unbatch().batch(3000).as_numpy_iterator())\n",
    "  accurate_count = 0\n",
    "#   tf.print(test_labels)\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == test_labels[0][index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  c_accurate_count = 0\n",
    "#   tf.print(test_labels)\n",
    "  for index in range(len(prediction_chars)):\n",
    "#     tf.print(prediction_chars[index][:-1],test_labels[1][index][:-1])\n",
    "    if prediction_chars[index][-1] == -1:\n",
    "        if prediction_chars[index][:-1].tolist() == test_labels[1][index][:-1].tolist():\n",
    "          c_accurate_count += 1\n",
    "    else:\n",
    "        if prediction_chars[index].tolist() == test_labels[1][index].tolist():\n",
    "          c_accurate_count += 1\n",
    "  c_accuracy = c_accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  return accuracy,c_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9676666666666667, 0.9593333333333334)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(interpreter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9666666666666667, 0.9616666666666667)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(interpreter_quant))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
